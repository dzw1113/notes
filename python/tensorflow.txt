
python第三方库
https://www.lfd.uci.edu/~gohlke/pythonlibs/ 


极客学院中文版tensorflow文档，tensor对应的是python的ndarray对象
http://wiki.jikexueyuan.com/project/tensorflow-zh/get_started/basic_usage.html
一个 TensorFlow 图描述了计算的过程. 为了进行计算, 图必须在 会话 里被启动. 会话 将图的 op 分发到诸如 CPU 或 GPU 之类的 设备 上, 同时提供执行 op 的方法. 
这些方法执行后, 将产生的 tensor 返回. 在 Python 语言中, 返回的 tensor 是 numpy ndarray 对象; 在 C 和 C++ 语言中, 返回的 tensor 是 tensorflow::Tensor 实例.

tensorflow-win7安装
https://tensorflow.google.cn/install/install_windows

先安装CUDA
https://developer.nvidia.com/cuda-downloads
http://www.linuxidc.com/Linux/2016-12/138862.htm
http://blog.csdn.net/dou3516/article/details/77836459
命令行校验：nvcc  -V



https://developer.nvidia.com/rdp/cudnn-download
下载cudnn-9.0-windows7-x64-v7,需要注册，解压zip包，把cuda里的文件夹覆盖到
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v9.0目录

 Tensorflow+cuda+cudnn+window+Python之window下安装TensorFlow
http://blog.csdn.net/flying_sfeng/article/details/58057400

 
安装tensorflow
python3 -m pip install tensorflow --trusted-host mirrors.aliyun.com

python3校验：
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()
>>> print(sess.run(hello))

语音训练和识别
http://blog.csdn.net/u014365862/article/details/53869701

kaldi上第一个免费的中文语音识别例子
http://blog.csdn.net/wbgxx333/article/details/50634571

中文语音数据库
https://github.com/kaldi-asr/kaldi/tree/master/egs/thchs30

清华大学cslt分享的数据库
https://pan.baidu.com/s/1dEhUghz#list/path=%2F


线性分类-支持向量机/support vector machine (SVM)完美解释
https://www.zhihu.com/question/21094489

莫烦学习
https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/1-3-what-does-NN-do/


http://blog.csdn.net/qq_34695147/article/details/70183480
感知器模型：
通俗的解释就是，期望在给定的数据集中，找到一个超平面，这个平面可以正确的分割开所有的数据类别。
这里有一个假设，就是这个超平面是一定存在的，就是一定是有解可以把这些数据集完好的分开。
这里先不列举数学公式，讲一讲通俗理解：
就是先初始化一个超平面，我认为这个超平面是分开了数据集，然后在利用数据集进行验算，如果发现数据集有错误分类的，
那么就利用梯度下降算法来纠正这个超平面，使它可以更好的划分。不断重复这个过程，直到没有任何一个点被误判，这时候我们就找到了我们需要的平面了。


VC维的理解
https://www.zhihu.com/question/38607822


卷积神经网络 CNN (Convolutional Neural Network)：它也被应用在视频分析, 自然语言处理, 药物发现, 等等. 近期最火的 Alpha Go, 让计算机看懂围棋
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-2-CNN/

循环神经网络 RNN (Recurrent Neural Network)：有了这些不同形式的 RNN, RNN 就变得强大了. 有很多有趣的 RNN 应用. 比如之前提到的, 让 RNN 描述照片. 让 RNN 写学术论文, 让 RNN 写程序脚本, 让 RNN 作曲. 我们一般人甚至都不能分辨这到底是不是机器写出来的.
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-3-RNN/

LSTM RNN 循环神经网络 (LSTM)：
今天我们会来聊聊在普通RNN的弊端和为了解决这个弊端而提出的 LSTM 技术. LSTM 是 long-short term memory 的简称, 中文叫做 长短期记忆. 是当下最流行的 RNN 形式之一
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-4-LSTM/
梯度：
以二元函数为例。我们在登山的时候，水平位置和高度都是变化的。
那么我们从我们站的地方朝某个方向水平移动一米，那高度提升了多少呢？这个就是方向导数。
同样是水平移动一米，那哪个方向高度提升的最多？这个方向复合上那个高度，就可以看成一个向量了，起名叫梯度。


自编码 (Autoencoder)：图片降噪
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-5-autoencoder/

主成分分析（PCA）原理详解
http://blog.jobbole.com/109015/


生成对抗网络 (GAN)：Generative Adversarial Nets：这样训练出来的 Generator 可以有很多用途, 比如最近有人就拿它来生成各种卧室的图片.
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-6-GAN/

输入层、输出层以及隐藏层的特征转换过程理解，例如手写输入一个数字，提取特征，这个特征可能只有机器认识，但是他可以转换成我们人类认识的信息作为输出。
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-7-feature-representation/


神经网络=梯度下降=求导求微分中的梯度（优化模式：比如说牛顿法 (Newton’s method), 最小二乘法(Least Squares method), 梯度下降法 (Gradient Descent) 等等）
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-8-gradient-descent/

提高驾驶技术：用GAN去除(爱情)动作片中的马赛克和衣服
https://zhuanlan.zhihu.com/p/27199954?utm_medium=social&utm_source=qq

检验神经网络 (Evaluation)：学习模拟考试的时候都是100分，考试的时候却只有80分，缺少随机应变，该问题叫做过拟合，因为平常联系缺少扩展，解决过拟合也有很多方法 , 比如 l1, l2 正规化, dropout 方法
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-01-Evaluate-NN/

选择好特征 (Good Features)
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-03-choose-feature/


激励函数 (Activation Function):激励函数也就是为了解决我们日常生活中 不能用线性方程所概括的问题.
在卷积神经网络 Convolutional neural networks 的卷积层中, 推荐的激励函数是 relu. 
在循环神经网络中 recurrent neural networks, 推荐的是 tanh 或者是 relu (这个具体怎么选, 我会在以后 循环神经网络的介绍中在详细讲解).
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-04-activation-function/

过拟合 (Overfitting):在小数据量下识别很好，量大就出误差
解决方法：
方法一: 增加数据量
方法二：运用正规化. L1, l2 regularization等等，还有一种专门用在神经网络的正规化的方法, 叫作 dropout.
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-05-overfitting/


加速神经网络训练 (Speed Up Training)：
包括以下几种模式:
Stochastic Gradient Descent (SGD)：大图片进入神经网络，因为太大，训练起来很慢，可以把大图数据分成小批小批的
Momentum：醉汉
AdaGrad：不好穿的鞋子
RMSProp：醉汉+不好穿的鞋子
Adam：最优？？
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-06-speed-up-learning/


处理不均衡数据 (Imbalanced data)
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/3-07-imbalanced-data/


强化学习:---------------传统表格形式，状态之形式
Q Leaning(Q learning 也是一个决策过程)
Sarsa：在线学习法，跟q leaning差不多
Sarsa(lambda)：
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-03-q-learning/
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-04-sarsa/


强化学习：--------------接收外部动作，计算出q值
DQN（Deep Q Network）
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-06-DQN/


强化学习：Actor Critic
它合并了 以值为基础 (比如 Q learning) 和 以动作概率为基础 (比如 Policy Gradients) 两类强化学习算法
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-08-AC/

强化学习：Deep Deterministic Policy Gradient (DDPG)
actor critic 的提升方式 Deep Deterministic Policy Gradient (DDPG), DDPG 最大的优势就是能够在连续动作上更有效地学习
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-09-DDPG/

强化学习：Asynchronous Advantage Actor-Critic (A3C)
https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/4-10-A3C/